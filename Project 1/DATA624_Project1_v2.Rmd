---
title: "DATA 624 Project 1"
author: "Bharani Nittala"
date: "March 25, 2023"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE}
library(readxl)
library(fpp3)
library(ggfortify)
library(DataExplorer)
library(tidyverse)
library(gridExtra)
library(forecast)
library(dplyr)
```

##  Project 1 Description 

This project consists of 3 parts - two required and one bonus and is worth 15% of your grade.  The project is due at 11:59 PM on Sunday Mar 26.  I will accept late submissions with a penalty until the meetup after that when we review some projects.


## Part A – ATM Forecast, ATM624Data.xlsx

In part A, I want you to forecast how much cash is taken out of 4 different ATM machines for May 2010.  The data is given in a single file.  The variable ‘Cash’ is provided in hundreds of dollars, other than that it is straight forward.   I am being somewhat ambiguous on purpose to make this have a little more business feeling.  Explain and demonstrate your process, techniques used and not used, and your actual forecast.  I am giving you data via an excel file, please provide your written report on your findings, visuals, discussion and your R code via an RPubs link along with the actual.rmd file  Also please submit the forecast which you will put in an Excel readable file.
 
## PART A


### Data Exploration

We will first load the data, which I have saved in a local folder, and explore it.
Reading in the DATA

```{r message=FALSE, warning=FALSE}
ATMDATA <- read_excel("ATM624Data.xlsx")
head(ATMDATA)


RCFL <- read_excel("ResidentialCustomerForecastLoad-624.xlsx")
head(RCFL)
```

As we can observe in the table above, the variable "DATE" is of data type "POSIXct". We will have to convert it to date in order to work with the data.

```{r message=FALSE, warning=FALSE}
summary(ATMDATA)
```

```{r message=FALSE, warning=FALSE}
plot_missing(ATMDATA)
```

There are a few missing values for "ATM" but I believe these were left blank on purpose in order to enter the predictions later on for the month of May. Additionally, there are also a few missing values from "Cash" that we may need to address.

```{r message=FALSE, warning=FALSE}
ATMDATA[!complete.cases(ATMDATA),]

head(ATMDATA)

#fix the date - as you saw previously we need to make some adjustment to fix data

ATMDATA$DATE<-as.Date(ATMDATA$DATE, origin = "1899-12-30")

```
Note from above that of 19 entries(rows) we see that 14 are missing. For simplicity sake these are supposed to be removed. 

While still exploring the data we make a matrix of plox with a given data set

### Data Preparation

We will create a separate data set in order to maintain the original data and make all the necessary transformations there. First we'll transform the "DATE" variables into its corresponding data type date. We will also make "Cash" an integer as we know that ATMs do not dispense cents.

```{r message=FALSE, warning=FALSE}
atm <- ATMDATA %>%
  mutate(DATE = as_date(DATE), Cash = as.integer(Cash))
str(atm)
```

Since we are looking at 4 separate ATMs and the data does not provide their location, they may have varying amounts of cash withdrawn at varying different days. We will work with each ATM separately and each will have its own forecast for the month of May in 2010.

```{r message=FALSE, warning=FALSE}
atm1 <- atm %>%
  filter(ATM == "ATM1") %>%
  as_tsibble(index = DATE)


autoplot(atm1) +
  labs(title="ATM1", subtitle="Cash withdrawals per day", y="Hundreds USD")
```

```{r message=FALSE, warning=FALSE}
atm2 <- atm %>%
  filter(ATM == "ATM2") %>%
  as_tsibble(index = DATE)


autoplot(atm2) +
  labs(title="ATM2", subtitle="Cash withdrawals per day", y="Hundreds USD")
```

```{r message=FALSE, warning=FALSE}
atm3 <- atm %>%
  filter(ATM == "ATM3") %>%
  as_tsibble(index = DATE)


autoplot(atm3) +
  labs(title="ATM3", subtitle="Cash withdrawals per day", y="Hundreds USD")
```

```{r message=FALSE, warning=FALSE}
atm4 <- atm %>%
  filter(ATM == "ATM4") %>%
  as_tsibble(index = DATE)


autoplot(atm4) +
  labs(title="ATM4", subtitle="Cash withdrawals per day", y="Hundreds USD")
```

Based on our plots above, we can observe that "ATM1" and "ATM2" are time series that have constant variability, with no apparent trend and potential seasonality, but we will explore these more in detail with decompositions. However, "ATM3"seems to only have withdrawals for the last few days in the data. Lastly, "ATM4" has a clear outlier.

```{r message=FALSE, warning=FALSE}
which(atm4$Cash == 10919)
```

The outlier is found on row 285 of the 4th ATM time series. We will use the average to impute this number as it is obvious that this is an error.

The time series looks more like "ATM1" and "ATM2" now:

```{r message=FALSE, warning=FALSE}
atm4[285,3] <- round(mean(atm4$Cash),0)

autoplot(atm4) +
  labs(title="ATM4", subtitle="Cash withdrawals per day", y="Hundreds USD")
```

We also seem to have a few missing values on the "Cash" column for "ATM1" and "ATM2":

```{r message=FALSE, warning=FALSE}
sum(is.na(atm1$Cash))
sum(is.na(atm2$Cash))
sum(is.na(atm3$Cash))
sum(is.na(atm4$Cash))
```

The missing values are found on the rows below for each respective ATM

```{r message=FALSE, warning=FALSE}
which(is.na(atm1$Cash))
which(is.na(atm2$Cash))
```

```{r message=FALSE, warning=FALSE}
hist(atm1$Cash)
hist(atm2$Cash)
```

Since we don't see an evident skewness on the distribution of "Cash" for either ATM above, I will use the median to impute these values:

```{r message=FALSE, warning=FALSE}
atm1[44,3] <- round(median(atm1$Cash, na.rm=TRUE),0)
atm1[47,3] <- round(median(atm1$Cash, na.rm=TRUE),0)
atm1[53,3] <- round(median(atm1$Cash, na.rm=TRUE),0)
atm2[49,3] <- round(median(atm2$Cash, na.rm=TRUE),0)
atm2[55,3] <- round(median(atm2$Cash, na.rm=TRUE),0)
```

Additionally, we can look for a Box-Cox transformation for each series to help make them a little simpler:

```{r message=FALSE, warning=FALSE}
lambda1 <- atm1%>%
  features(Cash,features = guerrero)%>%
  pull(lambda_guerrero)

plot_trans1 <- atm1 %>%
  autoplot(box_cox(Cash, lambda1)) +
  labs(title="ATM1 TRANSFORMED", subtitle="Cash withdrawals per day", y="USD")

lambda2 <- atm2%>%
  features(Cash,features = guerrero)%>%
  pull(lambda_guerrero)

plot_trans2 <- atm2 %>%
  autoplot(box_cox(Cash, lambda2)) +
  labs(title="ATM2 TRANSFORMED", subtitle="Cash withdrawals per day", y="USD")

lambda3 <- atm3%>%
  features(Cash,features = guerrero)%>%
  pull(lambda_guerrero)

plot_trans3 <- atm3 %>%
  autoplot(box_cox(Cash, lambda3)) +
  labs(title="ATM3 TRANSFORMED", subtitle="Cash withdrawals per day", y="USD")

lambda4 <- atm4%>%
  features(Cash,features = guerrero)%>%
  pull(lambda_guerrero)

plot_trans4 <- atm4 %>%
  autoplot(box_cox(Cash, lambda4)) +
  labs(title="ATM4 TRANSFORMED", subtitle="Cash withdrawals per day", y="USD")

grid.arrange(plot_trans1, plot_trans2, plot_trans3, plot_trans4, nrow = 2)
```

The transformations helped scale down the time series of all ATMs.

### Build Model

Let's now look at the decomposition of each series to see if we have strong seasonality and perhaps differencing is required in the model. Since the magnitud of the seasonal components do not seem to change with time, we can say the series are additive. 

```{r message=FALSE, warning=FALSE}
atm1%>%
  model(classical_decomposition(box_cox(Cash, lambda1), type="additive")) %>%
  components () %>%
  autoplot() + 
  labs(title="Classical additive decomposition of ATM1")
```

```{r message=FALSE, warning=FALSE}
atm2%>%
  model(classical_decomposition(box_cox(Cash, lambda2), type="additive")) %>%
  components () %>%
  autoplot() + 
  labs(title="Classical additive decomposition of ATM2")
```

```{r message=FALSE, warning=FALSE}
atm3%>%
  model(classical_decomposition(box_cox(Cash, lambda3), type="additive")) %>%
  components () %>%
  autoplot() + 
  labs(title="Classical additive decomposition of ATM3")
```

```{r message=FALSE, warning=FALSE}
atm4%>%
  model(classical_decomposition(box_cox(Cash, lambda4), type="additive")) %>%
  components () %>%
  autoplot() + 
  labs(title="Classical additive decomposition of ATM4")
```

As evident on the plots above, we see a strong seasonal component for all ATMs. 

```{r message=FALSE, warning=FALSE}
plot_acf1 <- atm1 %>%
  ACF(box_cox(Cash, lambda1)) %>%
  autoplot() + labs(title="Autocorrelation of Cash ATM1")

plot_acf2 <- atm2 %>%
  ACF(box_cox(Cash, lambda2)) %>%
  autoplot() + labs(title="Autocorrelation of Cash ATM2")

plot_acf3 <- atm3 %>%
  ACF(box_cox(Cash, lambda3)) %>%
  autoplot() + labs(title="Autocorrelation of Cash ATM3")

plot_acf4 <- atm4 %>%
  ACF(box_cox(Cash, lambda4)) %>%
  autoplot() + labs(title="Autocorrelation of Cash ATM4")

grid.arrange(plot_acf1, plot_acf2, plot_acf3, plot_acf4, nrow = 2)
```

As observed in the ACF plots above, we may need to apply `unitroot_nsdiffs()` to the daily cash withdrawals for each ATM in order to determine if we need any seasonal differencing by week.

```{r message=FALSE, warning=FALSE}
atm1 %>%
  features(box_cox(Cash, lambda1), unitroot_nsdiffs)
atm2 %>%
  features(box_cox(Cash, lambda2), unitroot_nsdiffs)
atm3 %>%
  features(box_cox(Cash, lambda3), unitroot_nsdiffs)
atm4 %>%
  features(box_cox(Cash, lambda4), unitroot_nsdiffs)
```

As determined by the function above, we need to apply seasonal differencing to "ATM1" and "ATM2". Let's explore further to see if we need any additional differencing:

```{r message=FALSE, warning=FALSE}
atm1 %>%
  features(difference(box_cox(Cash, lambda1), 7), unitroot_ndiffs)
atm2 %>%
  features(difference(box_cox(Cash, lambda2), 7), unitroot_ndiffs)
atm3 %>%
  features(box_cox(Cash, lambda3), unitroot_ndiffs)
atm4 %>%
  features(box_cox(Cash, lambda4), unitroot_ndiffs)
```

No additional differencing seems to be needed. Let's take a look at the ACF plots aftering differencing "ATM1" and "ATM2".

```{r message=FALSE, warning=FALSE}
atm1 %>%
  ACF(difference(box_cox(Cash, lambda1), 7)) %>%
  autoplot() + labs(title="Autocorrelation of Cash ATM1")
atm2 %>%
  ACF(difference(box_cox(Cash, lambda2), 7)) %>%
  autoplot() + labs(title="Autocorrelation of Cash ATM2")
```

Differencing seems to have made the data look closer to white noise.

Considering that these data need differencing, we will use the `ARIMA()` model, which applies differencing within the algorithm, making it simpler to build.

For "ATM3" we will use the naive model, which takes the last observation to forecast. Given there are only three values, this is a sound approach.

```{r message=FALSE, warning=FALSE}
atm1_fit <- atm1 %>%
  model(ARIMA(box_cox(Cash, lambda1)))

report(atm1_fit)

atm1_fit %>%
  gg_tsresiduals()
```

```{r message=FALSE, warning=FALSE}
atm2_fit <- atm2 %>%
  model(ARIMA(box_cox(Cash, lambda2)))

report(atm2_fit)

atm2_fit %>%
  gg_tsresiduals()
```

```{r message=FALSE, warning=FALSE}
atm3_fit <- atm3 %>%
  model(NAIVE(box_cox(Cash, lambda3)))

report(atm3_fit)

atm3_fit %>%
  gg_tsresiduals()
```

```{r message=FALSE, warning=FALSE}
atm4_fit <- atm4 %>%
  model(ARIMA(box_cox(Cash, lambda4)))

report(atm4_fit)

atm4_fit %>%
  gg_tsresiduals()
```

All residuals, except for "ATM3", look like they have constant variability, seem to be white noise and have approximately close to normal distributions.

### Forecasts


Finally, we save the forecast of each ATM in its own .csv document:

```{r message=FALSE, warning=FALSE}
forecast_atm1 <- atm1_fit %>% forecast(h=31)
forecast_atm2 <- atm2_fit %>% forecast(h=31)
forecast_atm3 <- atm3_fit %>% forecast(h=31)
forecast_atm4 <- atm4_fit %>% forecast(h=31)

write.csv(forecast_atm1,"forecast_atm1.csv")
write.csv(forecast_atm2,"forecast_atm2.csv")
write.csv(forecast_atm3,"forecast_atm3.csv")
write.csv(forecast_atm4,"forecast_atm4.csv")
```


## PART B

### Part B – Forecasting Power, ResidentialCustomerForecastLoad-624.xlsx

Part B consisx of a simple dataset of residential power usage for January 1998 until December 2013.  Your assignment is to model these data and a monthly forecast for 2014.  The data is given in a single file.  The variable ‘KWH’ is power consumption in Kilowatt hours, the rest is straight forward.    Add this to your existing files above. 

```{r}
head(RCFL)

summary(RCFL)
```

LOCATING THE MISSING VALUES
```{r}
which(is.na(RCFL), arr.ind=TRUE)

# aka 861 - 2008-Sep
```



```{r}
slice(RCFL,c(127:132))

#HERE YOU CAN WITNESS THE MISSING (NA) DATA 
```
There is missing data for 2008 SEPT

There seems to be data points near 2010
```{r}
RCFL_data <- RCFL %>% rename(Date = 'YYYY-MMM')
RCFL_data <- RCFL_data %>%  mutate(Date = as.Date(paste0('01-', Date), '%d-%Y-%b'))
min(RCFL_data$KWH,na.rm = TRUE)

```

```{r}
RCFL_2 <-ts(RCFL[, "KWH"], start = c(1998, 1), frequency = 12)
ggseasonplot(RCFL_2)+ggtitle('USAGE BY YEAR FOR RESIDENTIAL POWER')

```

BEING THAT THE DATE APPEARS SEASONAL, I THNINK WE COULD USE MEAN VALUE OF THE MONTHS JUNE / NOV IN ORDER TO HANDLE MISSING
```{r}
RCFL_data<- RCFL_data[-c(129,151),]

#Get average by month
RCFL_data$Month <- months(RCFL_data$Date)
aggregate(KWH ~ Month, RCFL_data, mean)
```


```{r}
RCFL$KWH[is.na(RCFL$KWH)] = median(RCFL$KWH, na.rm=TRUE)

summary(RCFL)
```

```{r}
RCFL_ts <- ts(RCFL$KWH, start=c(1998,1), frequency = 12)
RCFL_ts
```


```{r}
ggtsdisplay(RCFL_ts, main="Monthly Power Consumption before transform")

```

### BOXCOX TRANSFORM

```{r}
RCFLS_BXCX <- RCFL_ts %>% BoxCox(lambda= 'auto')
ggtsdisplay(RCFLS_BXCX, main='MONTHLY POWER CONSUMER BXCX')

```

### Exploratory data analysis

```{r}
ggseasonplot(RCFLS_BXCX)

summary(RCFLS_BXCX)
```


```{r}
ggsubseriesplot(RCFLS_BXCX) 


ggAcf(RCFLS_BXCX)
```


LETS UTILIZE A BOX TEST TO TAKE A CLOSER LOOK

```{r}
Box.test(RCFLS_BXCX, type = c("Ljung-Box"))

summary(RCFLS_BXCX)


boxplot(RCFLS_BXCX~cycle(RCFLS_BXCX))

```

DIFFERENCING

```{r}

print(paste0("Suggested # of diff: ", ndiffs(RCFLS_BXCX)))

print(paste0("DIFF REQUIRED (SEASIONAL): ", ndiffs(diff(RCFLS_BXCX, lag=12))))


RCFL_PWR_DIFF <- RCFLS_BXCX %>% diff(lag = 12)
ggtsdisplay(RCFL_PWR_DIFF, main= "Monthly power consumption BXCX AND DIFF")
```    



LETS SEE A GRAPHIC FOR RES POWER USAGE BY YEAR
```{r}
ggseasonplot(RCFL_PWR_DIFF,polar = TRUE)+ggtitle('Residential Power Usage by Year')

plot(RCFL_PWR_DIFF)
```


###LET SEE A MOVING AVG

```{r}
autoplot(RCFL_PWR_DIFF, series="Data")+
  autolayer(ma(RCFL_PWR_DIFF, 12), series = "12 MTH Moving Avg")+ ggtitle("2014 MVING AVG")

```


## Forecast Models

### 1 STL - ANN NO DP

```{r}
#stlf - etsmodel
RCFLS_STL <- stlf(RCFL_PWR_DIFF, damped=FALSE, s.window = "periodic", robust=TRUE, h = 12)

# forecast plot
autoplot(RCFLS_STL) + autolayer(fitted(RCFLS_STL))
```


###2 STL - DP AADN

```{r}
#stlf - etsmodel estimation --- M, Ad, N is chosen.
RCFL_STL_DP <- stlf(RCFL_PWR_DIFF, damped=TRUE, s.window = "periodic", robust=TRUE, h = 12)

# forecast plot
autoplot(RCFL_STL_DP) + autolayer(fitted(RCFL_STL_DP))
```



###3 - ARIMA
```{r}
# auto.arima
arima_model <- auto.arima(RCFL_PWR_DIFF)

# forecast values
arima_model <- forecast(arima_model, h=20)

# forecast plot
autoplot(arima_model) + autolayer(fitted(arima_model))
```



###4 - ETS MNM

```{r}
RCFL_ETS<- ets(RCFL_PWR_DIFF)

# forecast plot
autoplot(forecast(RCFL_ETS
                , h=12)) + autolayer(fitted(RCFL_ETS
                                                    ))

```



### 5 EXP SMOOTH

```{r}
RCFL_FCST_PWR_S <- ses(RCFL_PWR_DIFF, h=12)
autoplot(RCFL_FCST_PWR_S)+
  autolayer(fitted(RCFL_FCST_PWR_S), series="Fitted")

```



### COMPARISON OF THE MODELS

```{r}
accuracy(RCFLS_STL)
checkresiduals(RCFLS_STL)
summary(RCFLS_STL)

accuracy(RCFL_STL_DP)
checkresiduals(RCFL_STL_DP)
summary(RCFL_STL_DP)

accuracy(arima_model)
checkresiduals(arima_model)
summary(arima_model)


accuracy(RCFL_ETS)
checkresiduals(RCFL_ETS)
summary(RCFL_ETS)

accuracy(RCFL_FCST_PWR_S)
checkresiduals(RCFL_FCST_PWR_S)
summary(RCFL_FCST_PWR_S)
```


If you look at ARIMA it based AIC it appears with best result. BIC dropped to 540. AIC it dropped to 524. RMSE has also dropped from 1.347 to 0.966. i think i'll take ARIMA model on this one. I'll go ahead and predict the values in csv as I am comfortable with the results of ARIMA.

```{r}

rslts_2 <- forecast(arima_model, h=12)
rslts_fin <- data.frame(rslts_2)

write.csv(rslts_fin,"results_rcfl.csv", row.names = FALSE)
```

<!------- Below is for removing excessive space in Rmarkdown | HTML formatting -------->

<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>